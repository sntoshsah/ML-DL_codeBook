{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torchmetrics import Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiLayerPerceptron(pl.LightningModule):\n",
    "\tdef __init__(self, image_shape=(1,28,28), hidden_units=(32,16)):\n",
    "\t\tsuper().__init__()\n",
    "\t\t# new pl attributes\n",
    "\t\tself.train_acc = Accuracy(task=\"multiclass\", num_classes=10)\n",
    "\t\tself.valid_acc = Accuracy(task=\"multiclass\", num_classes=10)\n",
    "\t\tself.test_acc = Accuracy(task=\"multiclass\", num_classes=10)\n",
    "\n",
    "\t\t# Model Similar to Previous section\n",
    "\t\tinput_size = image_shape[0] * image_shape[1] * image_shape[2]\n",
    "\t\tall_layers = [nn.Flatten()]\n",
    "\t\tfor hidden_unit in hidden_units:\n",
    "\t\t\tlayer = nn.Linear(input_size, hidden_unit)\n",
    "\t\t\tall_layers.append(layer)\n",
    "\t\t\tall_layers.append(nn.ReLU())\n",
    "\t\t\tinput_size = hidden_unit\n",
    "\t\tall_layers.append(nn.Linear(hidden_units[-1], 10))\n",
    "\t\tself.model = nn.Sequential(*all_layers)\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\t\tx = self.model(x)\n",
    "\t\treturn x\n",
    "\t\n",
    "\tdef training_step(self, batch, batch_idx):\n",
    "\t\tx,y = batch\n",
    "\t\tlogits = self(x)\n",
    "\t\tloss = nn.functional.cross_entropy(self(x), y)\n",
    "\t\tpreds = torch.argmax(logits, dim=1)\n",
    "\t\tself.train_acc.update(preds, y)\n",
    "\t\tself.log(\"train_loss\", loss, prog_bar=True)\n",
    "\t\treturn loss\n",
    "\t\n",
    "\tdef on_train_epoch_end(self):\n",
    "\t\tself.log(\"Training Acc :\", self.train_acc.compute())\n",
    "\n",
    "\tdef validation_step(self, batch, batch_idx):\n",
    "\t\tx,y = batch\n",
    "\t\tlogits = self(x)\n",
    "\t\tloss = nn.functional.cross_entropy(self(x), y)\n",
    "\t\tpreds = torch.argmax(logits, dim=1)\n",
    "\t\tself.valid_acc.update(preds, y)\n",
    "\t\tself.log(\"Validation Loss:\", loss, prog_bar=True)\n",
    "\t\tself.log(\"Validation Accuracy:\", self.valid_acc.compute(), prog_bar=True)\n",
    "\t\treturn loss\n",
    "\n",
    "\tdef test_step(self, batch, batch_idx):\n",
    "\t\tx,y = batch\n",
    "\t\tlogits = self(x)\n",
    "\t\tloss = nn.functional.cross_entropy(self(x), y)\n",
    "\t\tpreds = torch.argmax(logits, dim=1)\n",
    "\t\tself.test_acc.update(preds, y)\n",
    "\t\tself.log(\"Testing Loss:\", loss, prog_bar=True)\n",
    "\t\tself.log(\"Testing Accuracy:\", self.test_acc.compute(), prog_bar=True)\n",
    "\t\treturn loss\n",
    "\t\n",
    "\tdef configure_optimizers(self):\n",
    "\t\toptimizer = torch.optim.Adam(self.parameters(), lr = 0.001)\n",
    "\t\treturn optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up the data loaders for Lightning\n",
    "There are three main ways in which we can prepare the dataset for Lightning.\n",
    "* Make the dataset part of the model\n",
    "* Set up the data loaders as usual and feed them to the fit method of a lightning Trainer\n",
    "* Create a LightningDataModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using LightningDataModue approach\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTDataModule(pl.LightningDataModule):\n",
    "\tdef __init__(self, data_path=\"./mnist_images/\"):\n",
    "\t\tsuper().__init__()\n",
    "\t\tself.data_path = data_path\n",
    "\t\tself.transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "\tdef prepare_data(self) :\n",
    "\t\tMNIST(root=self.data_path, download=True)\n",
    "\n",
    "\tdef setup(self, stage=None):\n",
    "\t\t# stage is either fit, validate, test or predict\n",
    "\t\tmnist_all = MNIST(root=self.data_path, train=True, transform=self.transform, download=False)\n",
    "\t\tself.train, self.val = random_split(\n",
    "\t\t\tmnist_all, [55000, 5000], generator=torch.Generator().manual_seed(1)\n",
    "\t\t)\n",
    "\t\tself.test = MNIST(root=self.data_path, train=False, transform=self.transform, download=True)\n",
    "\n",
    "\tdef train_dataloader(self) :\n",
    "\t\treturn DataLoader(self.train, batch_size=64, num_workers=4)\n",
    "\t\n",
    "\tdef val_dataloader(self) :\n",
    "\t\treturn DataLoader(self.val, batch_size=64, num_workers=4)\n",
    "\t\n",
    "\tdef test_dataloader(self) :\n",
    "\t\treturn DataLoader(self.test, batch_size=64, num_workers=4)\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1)\n",
    "mnist_dm = MNISTDataModule()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnistclassifier = MultiLayerPerceptron()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Missing logger folder: /home/santosh/ML-DL_codeBook/Chapter_13/lightning_logs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type               | Params | Mode \n",
      "---------------------------------------------------------\n",
      "0 | train_acc | MulticlassAccuracy | 0      | train\n",
      "1 | valid_acc | MulticlassAccuracy | 0      | train\n",
      "2 | test_acc  | MulticlassAccuracy | 0      | train\n",
      "3 | model     | Sequential         | 25.8 K | train\n",
      "---------------------------------------------------------\n",
      "25.8 K    Trainable params\n",
      "0         Non-trainable params\n",
      "25.8 K    Total params\n",
      "0.103     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 860/860 [00:10<00:00, 81.75it/s, v_num=0, train_loss=0.084, Validation Loss:=0.177, Validation Accuracy:=0.944]  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=20` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 860/860 [00:10<00:00, 81.67it/s, v_num=0, train_loss=0.084, Validation Loss:=0.177, Validation Accuracy:=0.944]\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "\ttrainer = pl.Trainer(max_epochs=20,devices=1)\n",
    "else:\n",
    "\ttrainer = pl.Trainer(max_epochs=20)\n",
    "\n",
    "trainer.fit(model=mnistclassifier, datamodule=mnist_dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-3562779238095e9e\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-3562779238095e9e\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6009;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir lightning_logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Restoring states from the checkpoint path at lightning_logs/version_0/checkpoints/epoch=19-step=17200.ckpt\n",
      "/home/santosh/ML-DL_codeBook/.venv/lib/python3.10/site-packages/lightning_fabric/utilities/cloud_io.py:57: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "/home/santosh/ML-DL_codeBook/.venv/lib/python3.10/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:360: The dirpath has changed from '/home/santosh/ML-DL_codeBook/Chapter_13/lightning_logs/version_0/checkpoints' to '/home/santosh/ML-DL_codeBook/Chapter_13/lightning_logs/version_1/checkpoints', therefore `best_model_score`, `kth_best_model_path`, `kth_value`, `last_model_path` and `best_k_models` won't be reloaded. Only `best_model_path` will be reloaded.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type               | Params | Mode \n",
      "---------------------------------------------------------\n",
      "0 | train_acc | MulticlassAccuracy | 0      | train\n",
      "1 | valid_acc | MulticlassAccuracy | 0      | train\n",
      "2 | test_acc  | MulticlassAccuracy | 0      | train\n",
      "3 | model     | Sequential         | 25.8 K | train\n",
      "---------------------------------------------------------\n",
      "25.8 K    Trainable params\n",
      "0         Non-trainable params\n",
      "25.8 K    Total params\n",
      "0.103     Total estimated model params size (MB)\n",
      "Restored all states from the checkpoint at lightning_logs/version_0/checkpoints/epoch=19-step=17200.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|██████████| 860/860 [00:12<00:00, 70.75it/s, v_num=1, train_loss=0.028, Validation Loss:=0.213, Validation Accuracy:=0.947]    "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=30` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|██████████| 860/860 [00:12<00:00, 70.66it/s, v_num=1, train_loss=0.028, Validation Loss:=0.213, Validation Accuracy:=0.947]\n"
     ]
    }
   ],
   "source": [
    "# Loading model from saved checkpoint and retraining for an additional 10 epochs\n",
    "if torch.cuda.is_available():\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=30,\n",
    "        devices=1,\n",
    "        accelerator=\"gpu\"\n",
    "    )\n",
    "else:\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=30,\n",
    "        devices=1,\n",
    "        accelerator=\"cpu\"\n",
    "    )\n",
    "\n",
    "# Assuming you have a model and datamodule already defined\n",
    "# model = mnistclassifier (already defined)\n",
    "# mnist_dm = your_data_module (already defined)\n",
    "\n",
    "trainer.fit(model=mnistclassifier, datamodule=mnist_dm,ckpt_path=\"lightning_logs/version_0/checkpoints/epoch=19-step=17200.ckpt\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 157/157 [00:01<00:00, 125.96it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "    Testing Accuracy:       0.9513083100318909\n",
      "      Testing Loss:         0.1878414899110794\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'Testing Loss:': 0.1878414899110794,\n",
       "  'Testing Accuracy:': 0.9513083100318909}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing \n",
    "trainer.test(model=mnistclassifier, datamodule=mnist_dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
