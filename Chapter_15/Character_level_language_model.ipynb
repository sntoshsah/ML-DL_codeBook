{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 1143k  100 1143k    0     0   358k      0  0:00:03  0:00:03 --:--:--  358k\n"
     ]
    }
   ],
   "source": [
    "# Data Collection\n",
    "!curl -O https://www.gutenberg.org/files/1268/1268-0.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total length:  1130711\n",
      "Unique Characters: 85\n"
     ]
    }
   ],
   "source": [
    "# Reading and preprocessing text\n",
    "with open(\"../Chapter_15/1268-0.txt\", \"r\", encoding=\"utf-8\") as fp:\n",
    "\ttext = fp.read()\n",
    "\n",
    "start_idx = text.find(\"THE MYSTERIOUS ISLAND\")\n",
    "end_idx = text.find(\"End of the Project Gutenberg\")\n",
    "text = text[start_idx:end_idx]\n",
    "char_set = set(text)\n",
    "print(\"total length: \", len(text))\n",
    "print(\"Unique Characters:\", len(char_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text encoded shape:  (1130711,)\n"
     ]
    }
   ],
   "source": [
    "chars_sorted = sorted(char_set)\n",
    "char2int = {ch:i for i,ch in enumerate(chars_sorted)}\n",
    "char_array = np.array(chars_sorted)\n",
    "text_encoded = np.array(\n",
    "\t[char2int[ch] for ch in text], dtype=np.int32\n",
    ")\n",
    "print(\"Text encoded shape: \", text_encoded.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THE MYSTERIOUS  == Encoding ==> [48 36 33  1 41 53 47 48 33 46 37 43 49 47  1]\n"
     ]
    }
   ],
   "source": [
    "print(text[:15], \"== Encoding ==>\", text_encoded[:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[37 47 40 29 42 32] == Reverse ==> ISLAND\n"
     ]
    }
   ],
   "source": [
    "print(text_encoded[15:21], \"== Reverse ==>\",''.join(char_array[text_encoded[15:21]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48->T\n",
      "36->H\n",
      "33->E\n",
      "1-> \n",
      "41->M\n"
     ]
    }
   ],
   "source": [
    "for ex in text_encoded[:5]:\n",
    "\tprint(\"{}->{}\".format(ex,char_array[ex]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([48, 36, 33,  1, 41, 53, 47, 48, 33, 46, 37, 43, 49, 47,  1, 37, 47,\n",
       "        40, 29, 42, 32,  1, 10, 10, 10,  0,  0,  0,  0,  0, 48, 36, 33,  1,\n",
       "        41, 53, 47, 48, 33, 46, 37], dtype=int32),\n",
       " array([36, 33,  1, 41, 53, 47, 48, 33, 46, 37, 43, 49, 47,  1, 37, 47, 40,\n",
       "        29, 42, 32,  1, 10, 10, 10,  0,  0,  0,  0,  0, 48, 36, 33,  1, 41,\n",
       "        53, 47, 48, 33, 46, 37, 43], dtype=int32),\n",
       " array([33,  1, 41, 53, 47, 48, 33, 46, 37, 43, 49, 47,  1, 37, 47, 40, 29,\n",
       "        42, 32,  1, 10, 10, 10,  0,  0,  0,  0,  0, 48, 36, 33,  1, 41, 53,\n",
       "        47, 48, 33, 46, 37, 43, 49], dtype=int32),\n",
       " array([ 1, 41, 53, 47, 48, 33, 46, 37, 43, 49, 47,  1, 37, 47, 40, 29, 42,\n",
       "        32,  1, 10, 10, 10,  0,  0,  0,  0,  0, 48, 36, 33,  1, 41, 53, 47,\n",
       "        48, 33, 46, 37, 43, 49, 47], dtype=int32),\n",
       " array([41, 53, 47, 48, 33, 46, 37, 43, 49, 47,  1, 37, 47, 40, 29, 42, 32,\n",
       "         1, 10, 10, 10,  0,  0,  0,  0,  0, 48, 36, 33,  1, 41, 53, 47, 48,\n",
       "        33, 46, 37, 43, 49, 47,  1], dtype=int32)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data Preprocessing\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "seq_length = 40\n",
    "chunk_size = seq_length+1\n",
    "text_chunks = [text_encoded[i:i+chunk_size] for i in range(len(text_encoded)-chunk_size)]\n",
    "text_chunks[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input (x): 'THE MYSTERIOUS ISLAND ***\\n\\n\\n\\n\\nTHE MYSTER'\n",
      "Target (y): 'HE MYSTERIOUS ISLAND ***\\n\\n\\n\\n\\nTHE MYSTERI'\n",
      "\n",
      "Input (x): 'HE MYSTERIOUS ISLAND ***\\n\\n\\n\\n\\nTHE MYSTERI'\n",
      "Target (y): 'E MYSTERIOUS ISLAND ***\\n\\n\\n\\n\\nTHE MYSTERIO'\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_33139/3839401018.py:12: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
      "  seq_dataset = TextDataset(torch.tensor(text_chunks))\n"
     ]
    }
   ],
   "source": [
    "class TextDataset(Dataset):\n",
    "\tdef __init__(self, text_chunks):\n",
    "\t\tself.text_chunks = text_chunks\n",
    "\n",
    "\tdef len(self):\n",
    "\t\treturn len(self.text_chunks)\n",
    "\t\n",
    "\tdef __getitem__(self, index):\n",
    "\t\ttext_chunk = self.text_chunks[index]\n",
    "\t\treturn text_chunk[:-1].long(), text_chunk[1:].long()\n",
    "\t\n",
    "seq_dataset = TextDataset(torch.tensor(text_chunks))\n",
    "\n",
    "for i, (seq, target) in enumerate(seq_dataset):\n",
    "\tprint(\"Input (x):\", repr(''.join(char_array[seq])))\n",
    "\tprint(\"Target (y):\", repr(''.join(char_array[target])))\n",
    "\tprint()\n",
    "\tif i == 1:\n",
    "\t\tbreak\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "batch_size = 32\n",
    "torch.manual_seed(1)\n",
    "seq_dl = DataLoader(list(seq_dataset), batch_size, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building a Character Level RNN Model\n",
    "import torch.nn as nn\n",
    "class RNN(nn.Module):\n",
    "\tdef __init__(self, vocab_size, embed_dim, rnn_hidden_size):\n",
    "\t\tsuper().__init__()\n",
    "\t\tself.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "\t\tself.rnn_hidden_size = rnn_hidden_size\n",
    "\t\tself.rnn = nn.LSTM(embed_dim,rnn_hidden_size,batch_first=True)\n",
    "\t\tself.fc = nn.Linear(rnn_hidden_size, vocab_size)\n",
    "\n",
    "\tdef forward(self, x, hidden, cell):\n",
    "\t\tout = self.embedding(x).unsqueeze(1)\n",
    "\t\tout,(hidden, cell) = self.rnn(out, (hidden, cell))\n",
    "\t\tout = self.fc(out).reshape(out.size(0), -1)\n",
    "\t\treturn out, hidden, cell\n",
    "\t\n",
    "\tdef init_hidden(self, batch_size):\n",
    "\t\thidden = torch.zeros(1, batch_size, self.rnn_hidden_size)\n",
    "\t\tcell = torch.zeros(1,batch_size, self.rnn_hidden_size)\n",
    "\t\treturn hidden, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN(\n",
       "  (embedding): Embedding(85, 256)\n",
       "  (rnn): LSTM(256, 512, batch_first=True)\n",
       "  (fc): Linear(in_features=512, out_features=85, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(char_array)\n",
    "embed_dim = 256\n",
    "rnn_hidden_size = 512\n",
    "torch.manual_seed(1)\n",
    "model = RNN(vocab_size, embed_dim,rnn_hidden_size)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0 Loss :2.0109\n",
      "Epoch : 50 Loss :1.9667\n",
      "Epoch : 100 Loss :1.8885\n",
      "Epoch : 150 Loss :1.7178\n",
      "Epoch : 200 Loss :1.6165\n",
      "Epoch : 250 Loss :1.6553\n",
      "Epoch : 300 Loss :1.5549\n",
      "Epoch : 350 Loss :1.5901\n",
      "Epoch : 400 Loss :1.5912\n",
      "Epoch : 450 Loss :1.4833\n"
     ]
    }
   ],
   "source": [
    "import torch.utils\n",
    "import torch.utils.tensorboard\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "writer = SummaryWriter(\"runs/Character_runs/\")\n",
    "num_epochs = 500\n",
    "for epoch in range(num_epochs):\n",
    "\thidden, cell = model.init_hidden(batch_size)\n",
    "\tseq_batch, target_batch = next(iter(seq_dl))\n",
    "\toptimizer.zero_grad()\n",
    "\tloss = 0\n",
    "\tfor c in range(seq_length):\n",
    "\t\tpred, hidden, cell = model(seq_batch[:,c], hidden, cell)\n",
    "\t\tloss += loss_fn(pred, target_batch[:,c])\n",
    "\tloss.backward()\n",
    "\toptimizer.step()\n",
    "\tloss = loss.item()/seq_length\n",
    "\tif epoch % 50 == 0:\n",
    "\t\tprint(f\"Epoch : {epoch} Loss :{loss:.4f}\")\n",
    "\twriter.add_scalar(\"Training Loss\", loss, epoch)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities: [0.33333334 0.33333334 0.33333334]\n",
      "[[0]\n",
      " [0]\n",
      " [0]\n",
      " [2]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [2]\n",
      " [0]\n",
      " [2]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluating phase - Generating new text passages\n",
    "from torch.distributions.categorical import Categorical\n",
    "logits = torch.tensor([[1.0,1.0,1.0]])\n",
    "print(\"Probabilities:\", nn.functional.softmax(logits, dim=1).numpy()[0])\n",
    "m = Categorical(logits=logits)\n",
    "samples = m.sample((10,))\n",
    "print(samples.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities: [0.10650698 0.10650698 0.78698605]\n",
      "[[2]\n",
      " [2]\n",
      " [0]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [1]\n",
      " [2]]\n"
     ]
    }
   ],
   "source": [
    "logits = torch.tensor([[1.0,1.0,3.0]])\n",
    "print(\"Probabilities:\", nn.functional.softmax(logits, dim=1).numpy()[0])\n",
    "m = Categorical(logits=logits)\n",
    "samples = m.sample((10,))\n",
    "print(samples.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(model, starting_str, len_generated_text=500,scale_factor=1.0):\n",
    "\tencoded_input = torch.tensor(\n",
    "\t\t[char2int[s] for s in starting_str]\n",
    "\t)\n",
    "\tencoded_input = torch.reshape(\n",
    "\t\tencoded_input, (1,-1)\n",
    "\t)\n",
    "\tgenerated_str = starting_str\n",
    "\n",
    "\tmodel.eval()\n",
    "\thidden, cell = model.init_hidden(1)\n",
    "\tfor c in range(len(starting_str)-1):\n",
    "\t\t_, hidden, cell = model(\n",
    "\t\t\tencoded_input[:,c].view(1), hidden, cell\n",
    "\t\t)\n",
    "\tlast_char = encoded_input[:, -1]\n",
    "\tfor c in range(len_generated_text):\n",
    "\t\tlogits, hidden, cell = model(\n",
    "\t\t\tlast_char.view(1), hidden, cell\n",
    "\t\t)\n",
    "\t\tlogits = torch.squeeze(logits, 0)\n",
    "\t\tscaled_logits = logits*scale_factor\n",
    "\t\tm = Categorical(logits=scaled_logits)\n",
    "\t\tlast_char = m.sample()\n",
    "\t\tgenerated_str += str(char_array[last_char])\n",
    "\treturn generated_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It was Found,\n",
      "orenough the gran in the good all begt his prevable\n",
      "sailor lazed the rechimented low’t loward\n",
      "Harding to taking and make as\n",
      "hey nabreards\n",
      "was in Captain a Chatter, no hearge bord, the lave aften by aimal. from the islet had on o’clorcy.\n",
      "\n",
      "At I\n",
      "chirest-gut be\n",
      "did the tabor doing.\n",
      "\n",
      "“A pieff nature\n",
      "fuch innithan which. The mose, by than manter, which it, therewn yet did give man?” replied Pendroved bay, which habumbited. The forrally some leme a rrest secence malures in some vold over it. But that\n"
     ]
    }
   ],
   "source": [
    "print(sample(model, starting_str=\"It was Found\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities before Scaling:  [0.10650698 0.10650698 0.78698605]\n",
      "Probabilities after Scaling with 0.5:  [0.21194156 0.21194156 0.57611686]\n",
      "Probabilities after Scaling with 0.1:  [0.3104238  0.3104238  0.37915248]\n"
     ]
    }
   ],
   "source": [
    "logits = torch.tensor([[1.0,1.0,3.0]])\n",
    "print(\"Probabilities before Scaling: \", nn.functional.softmax(logits, dim=1).numpy()[0])\n",
    "print(\"Probabilities after Scaling with 0.5: \", nn.functional.softmax(0.5*logits, dim=1).numpy()[0])\n",
    "print(\"Probabilities after Scaling with 0.1: \", nn.functional.softmax(0.1*logits, dim=1).numpy()[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It was Found be summined on the island. The shape of the shourced and a beand still the preported all gunting was a struck the sailor was sea. The from the firest for the shore of the propass, and as the sea. The stranger and herew did not his provision was neary of the fire been seep a strugge, and a wholes were the engineer and an more of the mate of the dar at the island. But it was not can the forest for a stall greation of the streath the engineer have been an arrow and not it was prodiced the more was\n"
     ]
    }
   ],
   "source": [
    "print(sample(model, starting_str=\"It was Found\", scale_factor=2.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It was FounddublaRiuj?”:.-R\n",
      "OVe\n",
      "vg-y6us Herbs!-AGStrak!-I-MMmukI0g\n",
      "CPurmo?\n",
      "The opicipCy\n",
      "Angmate any!” sixstout’s lave opuring ochic\n",
      "Payh,; “yo. GiditpAV, M.xNe, Mhpaul\n",
      "tyyruls \n",
      "Tunteej ts yauOjlsect\n",
      "faunsheq\"\n",
      "wad trohddel, coj melu; YOp.\n",
      "“Ap-baj!”’\n",
      "AnyoFne.\n",
      "\n",
      "HowTs pout sitate,, and\n",
      "knorscice:jA\n",
      "“rading,” xuppent feLItrm.\n",
      "A3\n",
      "togk cPanazon?” part\n",
      "of\n",
      "wicch pNery\n",
      "habd0k,-umodFUqa9)e,\n",
      "knok’g/.\n",
      "E1SODhb8T(”YAUvCTyQ\n",
      "et1”\n",
      "brepo\n",
      "as le-tok!”\n",
      "” row,”\n",
      "wahd Dll!”’-quatwea” ret Gucy!H-”“ITay\n",
      "A”\n",
      "Dlat\n",
      "Mazn?ZiVhatiw, “bvenif\n"
     ]
    }
   ],
   "source": [
    "print(sample(model, starting_str=\"It was Found\", scale_factor=0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
